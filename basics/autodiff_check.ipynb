{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ada22e5-bc2e-4e08-b42e-e87ce41f8d49",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b82e03-6a72-4875-8fb5-9fadb0360f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import jax.numpy as jnp\n",
    "from jax import grad\n",
    "import jax\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "from grad import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee48bf",
   "metadata": {},
   "source": [
    "# Test of my autodiff library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26de7cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Number(0.8807970779778823), Number(1.1353352832366128), Number(0.1353352832366127), Number(-2.0), Number(2.0), Number(-1), Number(2.718281828459045), Number(1), Number(1)]\n",
      "value comparison: Mine Number(0.8807970779778823) Jax 0.8807970285415649\n",
      "Grad comparison: Mine [0.1049935854035065] Jax[0.10499357]\n"
     ]
    }
   ],
   "source": [
    "testmine = Number(2.)\n",
    "mysigmoid = 1/(1+math.e**-testmine)\n",
    "\n",
    "mysigmoid.backprop(should_print=False)\n",
    "print(topo_sort(mysigmoid))\n",
    "\n",
    "def jaxsigmoidsum(x):\n",
    "    x = jnp.sum(x)\n",
    "    return 1 / (1 + jnp.exp(-x)) \n",
    "\n",
    "testjax = jnp.array([2.]) \n",
    "sigmoided_value, grads = jax.value_and_grad(jaxsigmoidsum, argnums=(0))(testjax)\n",
    "\n",
    "print(f\"value comparison:\", f\"Mine {mysigmoid}\", f\"Jax {sigmoided_value}\")\n",
    "print(f\"Grad comparison:\", f\"Mine {[testmine.grad]}\", f\"Jax{grads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc804d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jax_sigmoid(x):\n",
    "    return jnp.vectorize(lambda x: 1/(1+math.e**-x))(x)\n",
    "\n",
    "def jax_weight_matrix(shape, naive=False):\n",
    "    \"\"\"weight matrix thingy.give dims. Not 0.\"\"\"\n",
    "    number = 1\n",
    "    if(type(shape) == int):\n",
    "        shape = [shape]\n",
    "    for i in shape:\n",
    "        number*= i\n",
    "    if naive:\n",
    "        return jnp.array([(i / 10) for i in range(number)]).reshape(*shape)\n",
    "    return np.array([np.random.uniform(low=-.2, high=.2, size=None) for i in range(number)]).reshape(*shape)\n",
    "    # return np.array([variable(np.random.uniform(low=-.2, high=.2, size=None)) for i in range(sizes[0] * sizes[1])).reshape(*shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec10c353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number(10.65)\n",
      "10.65\n",
      "[1.5       1.5       1.8000001 1.8000001 2.1       2.1       2.4\n",
      " 2.4       2.6999998 2.6999998]\n",
      "[1.5, 1.5, 1.8, 1.8, 2.0999999999999996, 2.0999999999999996, 2.4000000000000004, 2.4000000000000004, 2.7, 2.7]\n"
     ]
    }
   ],
   "source": [
    "test_shape = (3,5)\n",
    "test_jax = jax_weight_matrix(test_shape, naive=True)\n",
    "test_mine = weight_matrix(test_shape, naive=True)\n",
    "test_shape2 = (5, 2)\n",
    "test_jax2 = jax_weight_matrix(test_shape2, naive=True)\n",
    "test_mine2 = weight_matrix(test_shape2, naive=True)\n",
    "\n",
    "my_matmul = np.sum(test_mine @ test_mine2)\n",
    "def j_matmul(a, b):\n",
    "    thing = a @ b\n",
    "    return jnp.sum(thing)\n",
    "\n",
    "\n",
    "print(my_matmul)\n",
    "print(j_matmul(test_jax, test_jax2))\n",
    "\n",
    "j_matmuled, grads = jax.value_and_grad(j_matmul, argnums=(0, 1))(test_jax, test_jax2)\n",
    "\n",
    "my_matmul.backprop()\n",
    "\n",
    "print(grads[1].flatten())\n",
    "print([thing.grad for thing in test_mine2.flat])\n",
    "#These match almost exactly! Yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe71d89b-c6fb-4a9d-8eaa-f15e763836c4",
   "metadata": {},
   "source": [
    "# Overfitting a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd3817b-2859-4488-aa24-952606bae576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c7d2b-44bf-429b-818b-33a400c56644",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data(path=\"mnist.npz\", )\n",
    "indices = np.arange(len(x_train))\n",
    "np.random.shuffle(indices)\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]\n",
    "\n",
    "def batch(x, y, batch_size=32):\n",
    "    if len(x) % batch_size != 0:\n",
    "        x = x[:batch_size * (len(x)//batch_size)]\n",
    "        y=y[:batch_size*(len(x)//batch_size)]\n",
    "    return np.array_split(x, len(x) / batch_size, axis=0), np.array_split(y, len(y)/batch_size, axis=0)\n",
    "\n",
    "def fix_data(x, y):\n",
    "    x = x.reshape(x.shape[0], 28*28)/255\n",
    "    test = np.zeros((x.shape[0], 10))\n",
    "    test[np.arange(x.shape[0]),y] = 1\n",
    "    return (x, test)\n",
    "\n",
    "fixed_x, fixed_y = fix_data(x_train[:1], y_train[:1])\n",
    "b_x , b_y = batch(fixed_x, fixed_y, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdfd579-df78-4222-b44d-d6d4b477ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_model = Model(28*28, 10, [ 8, 16])\n",
    "datas = []\n",
    "for _epoch in range(100):\n",
    "    print(f\"starting epoch {_epoch}\")\n",
    "    datas.append(my_model.train_epoch(b_x, b_y, lr=1e-2, timer=False, batch_timer=False))\n",
    "#as you can see loss does go down and it manages to predict the single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f4c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to display img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b04aeb",
   "metadata": {},
   "source": [
    "# Attempt to actually train it on multiple images\n",
    "\n",
    "For reasons that are embedded in my terrible architecture decisions, this is very long. (These reasons include the topo sort not being cached, which would be fairly difficult to implement due to how Numbers() are created. I did not make this homemade autodiff library for speed or even to truly train something; I made it to understand autodiff, which I think it has suceeded in doing, as demonstrated by above cells.)\n",
    "\n",
    "Running any of the cells below may result in it taking over half an hour to an hour to truly train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca25994-ac22-460b-a803-cdd346687cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312.0\n"
     ]
    }
   ],
   "source": [
    "full_x, full_y = fix_data(x_train[:10000], y_train[:10000])\n",
    "full_b_x , full_b_y = batch(fixed_x, fixed_y)\n",
    "\n",
    "my_model = Model(28*28, 10, [ 8, 16])\n",
    "datas = []\n",
    "for _epoch in range(30):\n",
    "    print(f\"starting epoch {_epoch}\")\n",
    "    datas.append(my_model.train_epoch(b_x, b_y, lr=1e-2, timer=False, batch_timer=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b0d5a9-29d0-4a33-8ff4-145ca4db75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline  \n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "pic = 1\n",
    "for i, img in enumerate(x_test[:10]):\n",
    "  plt.subplot(2, 5, pic)\n",
    "  plt.axis('off')\n",
    "  predicted = my_model.fd(img.flat)\n",
    "  plt.title(f\"T {y_test[i]} mine {np.argmax(predicted)} \")\n",
    "  plt.imshow(img)\n",
    "  pic+= 1\n",
    "plt.show()\n",
    "#60% acc. Considering this is from nearly scratch not terrible "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
