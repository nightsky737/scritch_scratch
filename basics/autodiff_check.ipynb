{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ada22e5-bc2e-4e08-b42e-e87ce41f8d49",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b82e03-6a72-4875-8fb5-9fadb0360f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import jax.numpy as jnp\n",
    "from jax import grad\n",
    "import jax\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from grad import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee48bf",
   "metadata": {},
   "source": [
    "# Test of my autodiff library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ab9ded4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topologically sorted Values:  [Number(12), Number(3), Number(15), Number(5), Number(3), Number(2), Number(1)]\n",
      "Backprop with topological sort [(1, Number(12)), (-1, Number(3)), (1, Number(15)), (3, Number(5)), (5, Number(3)), (5, Number(2)), (5, Number(1))]\n",
      "Backprop from the value [(1, Number(12)), (-1, Number(3)), (1, Number(15)), (3, Number(5)), (5, Number(3)), (5, Number(2)), (5, Number(1))]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This bit deals with how the computation graph is managed. The two outputs should be the same.\n",
    "\n",
    "Here, Number is my from-near-scratch autodiff library, kind of like how torch.tensor() is\n",
    "'''\n",
    "x1 = Number(1)\n",
    "x2 = Number(2)\n",
    "x3 = Number(3)\n",
    "x4 = Number(4)\n",
    "x5 = Number(5)\n",
    "\n",
    "y = (x1+x2)*x5 - x3\n",
    "top_sorted = topo_sort(y)\n",
    "\n",
    "print(\"Topologically sorted Values: \", top_sorted)\n",
    "\n",
    "y.null_gradients()\n",
    "\n",
    "for num in top_sorted:\n",
    "    num.backprop_single()\n",
    "    \n",
    "print(\"Backprop with topological sort\", [(i.grad, i) for i in top_sorted])\n",
    "\n",
    "y.null_gradients()\n",
    "y.backprop()\n",
    "\n",
    "print(\"Backprop from the value\", [(i.grad, i) for i in top_sorted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26de7cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value comparison: Mine Number(0.8807970779778823) Jax 0.8807970285415649\n",
      "Grad comparison: Mine [0.1049935854035065] Jax[0.10499357]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "For the next 3 cells, me and jax compare values on functions critical to neural networks.\n",
    "'''\n",
    "\n",
    "testmine = Number(2.)\n",
    "mysigmoid = 1/(1+math.e**-testmine)\n",
    "\n",
    "mysigmoid.backprop(should_print=False)\n",
    "\n",
    "def jaxsigmoidsum(x):\n",
    "    x = jnp.sum(x)\n",
    "    return 1 / (1 + jnp.exp(-x)) \n",
    "\n",
    "testjax = jnp.array([2.]) \n",
    "sigmoided_value, grads = jax.value_and_grad(jaxsigmoidsum, argnums=(0))(testjax)\n",
    "\n",
    "print(f\"value comparison:\", f\"Mine {mysigmoid}\", f\"Jax {sigmoided_value}\")\n",
    "print(f\"Grad comparison:\", f\"Mine {[testmine.grad]}\", f\"Jax{grads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfc804d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jax_sigmoid(x):\n",
    "    return jnp.vectorize(lambda x: 1/(1+math.e**-x))(x)\n",
    "\n",
    "def jax_weight_matrix(shape, naive=False):\n",
    "    \"\"\"weight matrix thingy.give dims. Not 0.\"\"\"\n",
    "    number = 1\n",
    "    if(type(shape) == int):\n",
    "        shape = [shape]\n",
    "    for i in shape:\n",
    "        number*= i\n",
    "    if naive:\n",
    "        return jnp.array([(i / 10) for i in range(number)]).reshape(*shape)\n",
    "    return np.array([np.random.uniform(low=-.2, high=.2, size=None) for i in range(number)]).reshape(*shape)\n",
    "    # return np.array([variable(np.random.uniform(low=-.2, high=.2, size=None)) for i in range(sizes[0] * sizes[1])).reshape(*shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec10c353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My value Number(10.65)\n",
      "Jax's value 10.65\n",
      "Jax's grads [1.5       1.5       1.8000001 1.8000001 2.1       2.1       2.4\n",
      " 2.4       2.6999998 2.6999998]\n",
      "My grads [1.5, 1.5, 1.8, 1.8, 2.0999999999999996, 2.0999999999999996, 2.4000000000000004, 2.4000000000000004, 2.7, 2.7]\n"
     ]
    }
   ],
   "source": [
    "test_shape = (3,5)\n",
    "test_jax = jax_weight_matrix(test_shape, naive=True)\n",
    "test_mine = weight_matrix(test_shape, naive=True)\n",
    "test_shape2 = (5, 2)\n",
    "test_jax2 = jax_weight_matrix(test_shape2, naive=True)\n",
    "test_mine2 = weight_matrix(test_shape2, naive=True)\n",
    "\n",
    "my_matmul = np.sum(test_mine @ test_mine2)\n",
    "def j_matmul(a, b):\n",
    "    thing = a @ b\n",
    "    return jnp.sum(thing)\n",
    "\n",
    "\n",
    "print(\"My value\" , my_matmul)\n",
    "print(\"Jax's value\", j_matmul(test_jax, test_jax2))\n",
    "\n",
    "j_matmuled, grads = jax.value_and_grad(j_matmul, argnums=(0, 1))(test_jax, test_jax2)\n",
    "\n",
    "my_matmul.backprop()\n",
    "\n",
    "print(\"Jax's grads\" , grads[1].flatten())\n",
    "print(\"My grads\", [thing.grad for thing in test_mine2.flat])\n",
    "#These match almost exactly! Yay! Please don't ask about the formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe71d89b-c6fb-4a9d-8eaa-f15e763836c4",
   "metadata": {},
   "source": [
    "# Overfitting a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd3817b-2859-4488-aa24-952606bae576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data(path=\"mnist.npz\", )\n",
    "indices = np.arange(len(x_train))\n",
    "np.random.shuffle(indices)\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]\n",
    "\n",
    "def batch(x, y, batch_size=32):\n",
    "    if len(x) % batch_size != 0:\n",
    "        x = x[:batch_size * (len(x)//batch_size)]\n",
    "        y=y[:batch_size*(len(x)//batch_size)]\n",
    "    return np.array_split(x, len(x) / batch_size, axis=0), np.array_split(y, len(y)/batch_size, axis=0)\n",
    "\n",
    "def fix_data(x, y):\n",
    "    x = x.reshape(x.shape[0], 28*28)/255\n",
    "    test = np.zeros((x.shape[0], 10))\n",
    "    test[np.arange(x.shape[0]),y] = 1\n",
    "    return (x, test)\n",
    "\n",
    "fixed_x, fixed_y = fix_data(x_train[:1], y_train[:1]) #We take only one image\n",
    "b_x , b_y = batch(fixed_x, fixed_y, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cdfd579-df78-4222-b44d-d6d4b477ecce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 0\n",
      "Acc: 0.0 Avg loss: 2.5404272913700097\n",
      "Elapsed time for one epoch: 0.09765959996730089 seconds\n",
      "starting epoch 1\n",
      "Acc: 0.0 Avg loss: 2.4178759463385653\n",
      "Elapsed time for one epoch: 0.1118340000975877 seconds\n",
      "starting epoch 2\n",
      "Acc: 0.0 Avg loss: 2.3027330912420005\n",
      "Elapsed time for one epoch: 0.10104560013860464 seconds\n",
      "starting epoch 3\n",
      "Acc: 1.0 Avg loss: 2.1900675339014\n",
      "Elapsed time for one epoch: 0.3303846998605877 seconds\n",
      "starting epoch 4\n",
      "Acc: 1.0 Avg loss: 2.0775970999406512\n",
      "Elapsed time for one epoch: 0.10056080017238855 seconds\n",
      "starting epoch 5\n",
      "Acc: 1.0 Avg loss: 1.9638569088340436\n",
      "Elapsed time for one epoch: 0.1067631000187248 seconds\n",
      "starting epoch 6\n",
      "Acc: 1.0 Avg loss: 1.8481116547506435\n",
      "Elapsed time for one epoch: 0.32172450004145503 seconds\n",
      "starting epoch 7\n",
      "Acc: 1.0 Avg loss: 1.7302941843173607\n",
      "Elapsed time for one epoch: 0.09617669996805489 seconds\n",
      "starting epoch 8\n",
      "Acc: 1.0 Avg loss: 1.610939576989026\n",
      "Elapsed time for one epoch: 0.1012807001825422 seconds\n",
      "starting epoch 9\n",
      "Acc: 1.0 Avg loss: 1.4910912469470738\n",
      "Elapsed time for one epoch: 0.3235575999133289 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_model = Model(28*28, 10, [ 8, 16])\n",
    "datas = []\n",
    "for _epoch in range(10):\n",
    "    print(f\"starting epoch {_epoch}\")\n",
    "    datas.append(my_model.train_epoch(b_x, b_y, lr=.1, timer=False, batch_timer=False))\n",
    "#as you can see loss does go down and it manages to predict the single image.\n",
    "#I tried really hard to get it to be able to fully train on all images, but it takes a very long time (in the hours+). \n",
    "#Intended behavior: At first, the acc (accuracy) is 0 because it has no idea what it's doing. But over time, it fits to that image and predicts that image (Acc of 1). Yay!\n",
    "#Loss also does go down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db4e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f4c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to display img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b04aeb",
   "metadata": {},
   "source": [
    "# Attempt to actually train it on multiple images\n",
    "\n",
    "For reasons that are embedded in my terrible architecture decisions, this is very long. (These reasons include the topo sort not being cached, which would be fairly difficult to implement due to how Numbers() are created. I did not make this homemade autodiff library for speed or even to truly train something; I made it to understand autodiff, which I think it has suceeded in doing, as demonstrated by above cells.)\n",
    "\n",
    "Running any of the cells below may result in it taking over half an hour to an hour to truly train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ca25994-ac22-460b-a803-cdd346687cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312.0\n"
     ]
    }
   ],
   "source": [
    "full_x, full_y = fix_data(x_train[:10000], y_train[:10000])\n",
    "full_b_x , full_b_y = batch(fixed_x, fixed_y)\n",
    "\n",
    "my_model = Model(28*28, 10, [ 8, 16])\n",
    "datas = []\n",
    "for _epoch in range(30):\n",
    "    print(f\"starting epoch {_epoch}\")\n",
    "    datas.append(my_model.train_epoch(b_x, b_y, lr=1e-2, timer=False, batch_timer=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b0d5a9-29d0-4a33-8ff4-145ca4db75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline  \n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "pic = 1\n",
    "for i, img in enumerate(x_test[:10]):\n",
    "  plt.subplot(2, 5, pic)\n",
    "  plt.axis('off')\n",
    "  predicted = my_model.fd(img.flat)\n",
    "  plt.title(f\"T {y_test[i]} mine {np.argmax(predicted)} \")\n",
    "  plt.imshow(img)\n",
    "  pic+= 1\n",
    "plt.show()\n",
    "#60% acc. Considering this is from nearly scratch not terrible "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
