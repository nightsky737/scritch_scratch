{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24a9cc12-2578-4aef-8ee6-884ffab4f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grad import *\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc4ff80a-6930-4829-aa43-4236da9d571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_loss(truth, model):\n",
    "    ''' Simple L2 loss for a single sample.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        truth : Sequence[float]\n",
    "            A single data point.\n",
    "              \n",
    "        model : Sequence[float]\n",
    "            The parameters of a model.\n",
    "              \n",
    "        Returns\n",
    "        -------\n",
    "        Number : the L2 loss (squared error) of `model_params` evaluated on `truth`\n",
    "    '''\n",
    "    l = truth[0] - model[0] - sum(truth[i]*model[i] for i in range(1, len(model)))\n",
    "    return l**2 if l.data > 0 else (-1*l)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d30f6ee-fae9-4977-9c0d-a794d25066a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topo_sort(N):\n",
    "    '''Returns the correct order to backprop N in. Yes. This is such that if you call backprop(N), the gradient on N is final.\n",
    "    rets a list of Numbers.\n",
    "    \n",
    "    So ideally we'd just backprop one layer (to N's two creators (ie a and b when u backprop N in a * b = N) when we get to the N \n",
    "\n",
    "    *sigh* back to the usaco grind\n",
    "    '''\n",
    "    ret = []\n",
    "    visited = {}\n",
    "    def dfs(number):\n",
    "        '''\n",
    "        dfs's a Number, following it down the path by df'sing its two creators.\n",
    "        '''\n",
    "        if visited.get(number)== \"visited\":\n",
    "            return True\n",
    "        if visited.get(number) == \"visiting\":\n",
    "            return False\n",
    "        visited[number] = \"visiting\"\n",
    "        \n",
    "        if number.creator != None:\n",
    "            if not dfs(number.creator.a):\n",
    "                print(number, \" to \" , number.creator.a)\n",
    "            if not dfs(number.creator.b):\n",
    "                print(number, \" to \" , number.creator.b)\n",
    "        visited[number] = \"visited\"\n",
    "        ret.append(number)\n",
    "        return True\n",
    "        \n",
    "    dfs(N)\n",
    "    ret.reverse()\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f21584e9-684c-41a7-b705-dd07612aae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def weight_matrix(shape, naive=False):\n",
    "    \"\"\"weight matrix thingy.give dims. Not 0.\"\"\"\n",
    "    # np.as_array(Number(np.random.rand()) for i in range(M*N))\n",
    "    number = 1\n",
    "    if(type(shape) == int):\n",
    "        shape = [shape]\n",
    "    for i in shape:\n",
    "        number*= i\n",
    "    if naive:\n",
    "        return np.array([Number(i / 10) for i in range(number)]).reshape(*shape)\n",
    "    return np.array([Number(np.random.uniform(low=-.2, high=.2, size=None)) for i in range(number)]).reshape(*shape)\n",
    " \n",
    "def get_grads(x):\n",
    "    vectorized_grad = np.vectorize(lambda x : x.grad) #not true vecotrization just for readibility\n",
    "    return vectorized_grad(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.vectorize(lambda x: 1/(1+math.e**-x))(x)\n",
    "\n",
    "def relu(x):\n",
    "    # print(x)\n",
    "    def relu_one(k):\n",
    "        if k <= 0:\n",
    "            return 10e-2 * k\n",
    "        else:\n",
    "            return k\n",
    "    return np.vectorize(lambda x: relu_one(x))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c1818126-0bf2-4043-afd4-49f3025297f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    '''this only works w/ MSE and sigmoid because dik how to topological sort'''\n",
    "    \n",
    "    def __init__(self, input_size, output_size, hidden_layers, naive=False):\n",
    "        '''\n",
    "        Takes list of # of things in their layers.\n",
    "        Layers are outputs?\n",
    "        '''\n",
    "        self.layer_sizes = hidden_layers\n",
    "        self.layers = []\n",
    "        self.biases = []\n",
    "\n",
    "        #Hidden states is after the *weight but before sigmoid\n",
    "        self.hidden_states = []\n",
    "\n",
    "        self.hidden_states_sigmoid = []\n",
    "        \n",
    "        prev = input_size\n",
    "        for hidden_layer in hidden_layers:\n",
    "            # self.layers, weight_matrix([prev, hidden_layer])\n",
    "            self.layers.append(weight_matrix([prev, hidden_layer], naive))\n",
    "\n",
    "            self.biases.append(weight_matrix(hidden_layer, naive))\n",
    "            prev  = hidden_layer\n",
    "        self.biases.append(weight_matrix([output_size]))\n",
    "        self.layers.append(weight_matrix([prev, output_size]))\n",
    "  \n",
    "    def fd(self, x):\n",
    "        '''f pass with input. Input has to be flat like a pancake'''\n",
    "        #sigma sigma boy.\n",
    "        self.hidden_states_sigmoid = []\n",
    "        self.hidden_states = []\n",
    "        self.input = x\n",
    "        for i in range(len(self.layers)):\n",
    "            # print(np.max(x))\n",
    "            x = x @ self.layers[i]\n",
    "            x += self.biases[i]\n",
    "            self.hidden_states.append(x)\n",
    "            if i != len(self.layers) - 1:\n",
    "                x = relu(x)\n",
    "                # print(\"Non-zero ReLUs:\", np.count_nonzero(x))\n",
    "            else:\n",
    "                x = sigmoid(x)\n",
    "            self.hidden_states_sigmoid.append(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def train_epoch(self, x, y, lr=10**-2):\n",
    "        '''\n",
    "        f pass and then uh gradient descent?\n",
    "\n",
    "        x: Input. Again, flat as a pancake.\n",
    "        y: the goal. In sparese tensor. \n",
    "        lr: how quick it learns\n",
    "        '''\n",
    "        num_correct = 0\n",
    "        losses = []\n",
    "        for i in range(len(y)):\n",
    "        #     for layer in self.layers:\n",
    "        #         for w in layer.flat:\n",
    "        #             w.null_gradients(recursive=False)\n",
    "\n",
    "        #     for bias in self.biases:\n",
    "        #         for b in bias.flat:\n",
    "        #             b.null_gradients(recursive=False)\n",
    "                    \n",
    "            pred = self.fd(x[i])\n",
    "            # mse = np.sum((pred * pred +  y[i] *  y[i] - 2 * np.dot(pred, y[i]))) / len(y)\n",
    "            mse = sum((a - b)**2 for a, b in zip(pred, y[i]))\n",
    "\n",
    "            num_correct += np.argmax(pred) == np.argmax(y[i])\n",
    "            losses.append(mse)\n",
    "            mse_sorted = topo_sort(mse)\n",
    "            # print(f\"order {mse_sorted}\")\n",
    "            for num in mse_sorted:\n",
    "                num.backprop_single()\n",
    "            # print(\"Final layer pre-sigmoid:\", self.hidden_states[-1])\n",
    "\n",
    "            #These look ok.\n",
    "            # for i, layer in enumerate(self.layers):\n",
    "            #     for j, num in enumerate(layer.flat):\n",
    "            #         print(f\"Layer {i} Flat[{j}] grad: {num.grad}\")\n",
    "            #     for m, r in enumerate(layer):\n",
    "            #         for n, c in enumerate(r):\n",
    "            #             print(f\"Layer {i} Row {m} col {n} grad: {c.grad}\")\n",
    "            # self.print_info()\n",
    "            \n",
    "            #What in the FREAK is nulling the gradients here?????\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                for w in range(len(layer.flat)):\n",
    "                    layer.flat[w] = Number(layer.flat[w] - layer.flat[w].grad * lr)\n",
    "            #OH WAIT IT SHOULD BE NULL :sob: WE MAKING NEW NUMBERS. Cleans the graph too!\n",
    "            # self.print_info()\n",
    "\n",
    "            for i in range(len(self.biases)):\n",
    "                layer = self.biases[i]\n",
    "                for b in range(len(layer.flat)):\n",
    "                    layer.flat[b] = Number( layer.flat[b] - layer.flat[b].grad * lr)\n",
    "        print(f\"Acc: {num_correct/len(y)} Avg loss: {sum(losses)/len(y)}\")\n",
    "            # print(f\"Acc: {num_correct/len(y)} Avg loss: {losses}\")\n",
    "\n",
    "    def print_info(self, verbose=True):\n",
    "        print(\"layers \" )\n",
    "        for i in range(len(self.layers)):\n",
    "            print( f\"weight {i} of shape {self.layers[i].shape}\")\n",
    "            print(self.layers[i])\n",
    "            print(\"grads\")\n",
    "            print(np.vectorize(lambda x : x.grad)(self.layers[i]))\n",
    "            \n",
    "        print(\"biases \")\n",
    "        for i in range(len(self.biases)):\n",
    "            print( f\"bias {i} of shape {self.biases[i].shape}\")\n",
    "            print(self.biases[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "fe3b98f9-02a3-4805-aa29-09b98e9751dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.5 Avg loss: Number(0.5046219601608408)\n"
     ]
    }
   ],
   "source": [
    "tiny_x = [[1, 2], [2, 3]]\n",
    "tiny_test = Model(2, 2, [3, 1], naive=True)\n",
    "tiny_test.train_epoch(tiny_x, np.array( [[0, 1],[1, 0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e31d2937-3c69-4fdd-b71a-41185bc395ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.13 Avg loss: Number(1.291816224337269)\n",
      "Acc: 0.09 Avg loss: Number(0.922030117375282)\n",
      "Acc: 0.11 Avg loss: Number(0.9167681954888175)\n",
      "Acc: 0.11 Avg loss: Number(0.9131554217750134)\n",
      "Acc: 0.1 Avg loss: Number(0.9105261004876037)\n",
      "Acc: 0.1 Avg loss: Number(0.9084750528802458)\n",
      "Acc: 0.1 Avg loss: Number(0.9067768847705626)\n",
      "Acc: 0.11 Avg loss: Number(0.905306783956894)\n",
      "Acc: 0.12 Avg loss: Number(0.9039868066098039)\n",
      "Acc: 0.12 Avg loss: Number(0.9027607426123027)\n",
      "Acc: 0.13 Avg loss: Number(0.9015819329495318)\n",
      "Acc: 0.16 Avg loss: Number(0.9004054453628426)\n",
      "Acc: 0.19 Avg loss: Number(0.8991802753332253)\n",
      "Acc: 0.19 Avg loss: Number(0.8978373834696436)\n",
      "Acc: 0.19 Avg loss: Number(0.8962646341611017)\n",
      "Acc: 0.21 Avg loss: Number(0.8942399105721449)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[274], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m plsfuckingwork \u001b[38;5;241m=\u001b[39m Model(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m10\u001b[39m, [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     plsfuckingwork\u001b[38;5;241m.\u001b[39mtrain_epoch(fixed_x, fixed_y, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10e-2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[270], line 73\u001b[0m, in \u001b[0;36mModel.train_epoch\u001b[1;34m(self, x, y, lr)\u001b[0m\n\u001b[0;32m     71\u001b[0m num_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(pred) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y[i])\n\u001b[0;32m     72\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(mse)\n\u001b[1;32m---> 73\u001b[0m mse_sorted \u001b[38;5;241m=\u001b[39m topo_sort(mse)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# print(f\"order {mse_sorted}\")\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m mse_sorted:\n",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m, in \u001b[0;36mtopo_sort\u001b[1;34m(N)\u001b[0m\n\u001b[0;32m     27\u001b[0m     ret\u001b[38;5;241m.\u001b[39mappend(number)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m dfs(N)\n\u001b[0;32m     31\u001b[0m ret\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m, in \u001b[0;36mtopo_sort.<locals>.dfs\u001b[1;34m(number)\u001b[0m\n\u001b[0;32m     19\u001b[0m visited[number] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisiting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m number\u001b[38;5;241m.\u001b[39mcreator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs(number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39ma):\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(number, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m , number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39ma)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs(number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39mb):\n",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m, in \u001b[0;36mtopo_sort.<locals>.dfs\u001b[1;34m(number)\u001b[0m\n\u001b[0;32m     19\u001b[0m visited[number] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisiting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m number\u001b[38;5;241m.\u001b[39mcreator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs(number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39ma):\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(number, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m , number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39ma)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs(number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39mb):\n",
      "    \u001b[1;31m[... skipping similar frames: topo_sort.<locals>.dfs at line 22 (7 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36mtopo_sort.<locals>.dfs\u001b[1;34m(number)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs(number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39ma):\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(number, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m , number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39ma)\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs(number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39mb):\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(number, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m , number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39mb)\n\u001b[0;32m     26\u001b[0m visited[number] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisited\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "    \u001b[1;31m[... skipping similar frames: topo_sort.<locals>.dfs at line 22 (2 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36mtopo_sort.<locals>.dfs\u001b[1;34m(number)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs(number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39ma):\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(number, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m , number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39ma)\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs(number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39mb):\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(number, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m , number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39mb)\n\u001b[0;32m     26\u001b[0m visited[number] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisited\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "    \u001b[1;31m[... skipping similar frames: topo_sort.<locals>.dfs at line 22 (6 times), topo_sort.<locals>.dfs at line 24 (3 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36mtopo_sort.<locals>.dfs\u001b[1;34m(number)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs(number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39ma):\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(number, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m , number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39ma)\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs(number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39mb):\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(number, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m , number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39mb)\n\u001b[0;32m     26\u001b[0m visited[number] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisited\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "    \u001b[1;31m[... skipping similar frames: topo_sort.<locals>.dfs at line 22 (409 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m, in \u001b[0;36mtopo_sort.<locals>.dfs\u001b[1;34m(number)\u001b[0m\n\u001b[0;32m     19\u001b[0m visited[number] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisiting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m number\u001b[38;5;241m.\u001b[39mcreator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs(number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39ma):\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(number, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m , number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39ma)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs(number\u001b[38;5;241m.\u001b[39mcreator\u001b[38;5;241m.\u001b[39mb):\n",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m, in \u001b[0;36mtopo_sort.<locals>.dfs\u001b[1;34m(number)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdfs\u001b[39m(number):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    dfs's a Number, following it down the path by df'sing its two creators.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m visited\u001b[38;5;241m.\u001b[39mget(number)\u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisited\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m visited\u001b[38;5;241m.\u001b[39mget(number) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisiting\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\Downloads\\scritch_scratch\\basics\\grad.py:346\u001b[0m, in \u001b[0;36mNumber.__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m other\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5d06d00d-4655-4505-bb07-0f1eeb191763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1 [Number(1.0) Number(1.1)]\n",
      "k2 [[Number(0.3)]\n",
      " [Number(0.4)]]\n",
      "kb [Number(2.0)]\n",
      "f1 [Number(0.74)]\n",
      "f [Number(2.74)]\n",
      "[Number(2.74), Number(2.0), Number(0.74), Number(0.44000000000000006), Number(0.4), Number(1.1), Number(0.3), Number(0.3), Number(1.0)]\n",
      "a Number(0.74) + Number(0.3) Number(0.44000000000000006)\n"
     ]
    }
   ],
   "source": [
    "fake = np.array([Number(i/10 + 1) for i in range(2)])\n",
    "fake1 = np.array([Number(i/10 + .3) for i in range(2)]).reshape(2,1)\n",
    "fake_bias = np.array([Number(i/10 + 2) for i in range(1)])\n",
    "\n",
    "print(\"k1\" , fake)\n",
    "print(\"k2\" , fake1)\n",
    "print(\"kb\" , fake_bias)\n",
    "\n",
    "final1 = fake @ fake1 \n",
    "final = final1 + fake_bias\n",
    "print(\"f1\" , final1)\n",
    "\n",
    "print(\"f\" , final)\n",
    "\n",
    "idk = topo_sort(final[0])\n",
    "print(idk)\n",
    "for num in final1.flat:\n",
    "    print(\"a\" , num,num.creator, num.creator.a, num.creator.b)\n",
    "\n",
    "for num in final:\n",
    "    \n",
    "    num.backprop_single()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb3817-44e3-4ace-977b-f8df662af0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_x = [[1, 2, 3, 4]]\n",
    "tiny_test = Model(4, 1, [3], naive=True)\n",
    "tiny_test.print_info()\n",
    "tiny_test.train_epoch(tiny_x, np.array([2,3]))\n",
    "tiny_test.train_epoch(tiny_x, np.array([2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "734c4959-8b4f-4556-9c4a-26c7ed029f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_gradients(layers):\n",
    "    \"\"\"nulls all gradients\"\"\"\n",
    "    for layer in layers:\n",
    "        for weight in layer.flat:\n",
    "            weight.null_gradients()\n",
    "            \n",
    "def check_null(layers):\n",
    "    \"\"\"nulls all gradients\"\"\"\n",
    "    for layer in layers:\n",
    "        for weight in layer.flat:\n",
    "            if weight.grad != None:\n",
    "                print(\"hi welcome to another 5hrs of debuggin\")\n",
    "    print(\"passed null check \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b343a94-8b6b-4bef-b3e6-b86526c5a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_data(x, y):\n",
    "    x = x.reshape(x.shape[0], 28*28)/255\n",
    "    test = np.zeros((x.shape[0], 10))\n",
    "    test[np.arange(x.shape[0]),y] = 1\n",
    "    return (x, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e13c3bf4-97dd-4ed4-b50d-dfaaaffa040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "testx, testy = fix_data(x_train[0:2], y_train[0:2])\n",
    "rawx = x_train[0:2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "2a38e3b1-1efa-4616-92ad-2887f58d8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_x, fixed_y = fix_data(x_train[:1000], y_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "58e74a75-3a1e-457d-b458-a4666093bd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.193 Avg loss: Number(0.9148206999012773)\n",
      "Acc: 0.347 Avg loss: Number(0.7649153700637776)\n",
      "Acc: 0.417 Avg loss: Number(0.7048005599121263)\n",
      "Acc: 0.476 Avg loss: Number(0.659013730140775)\n",
      "Acc: 0.556 Avg loss: Number(0.6126583948084633)\n",
      "Acc: 0.619 Avg loss: Number(0.5233582602451018)\n",
      "Acc: 0.681 Avg loss: Number(0.4554136677357978)\n",
      "Acc: 0.7 Avg loss: Number(0.41836248180804436)\n",
      "Acc: 0.721 Avg loss: Number(0.40502758578499515)\n",
      "Acc: 0.722 Avg loss: Number(0.40834967394121585)\n",
      "Acc: 0.741 Avg loss: Number(0.3860735134187396)\n",
      "Acc: 0.757 Avg loss: Number(0.3879122382040642)\n",
      "Acc: 0.644 Avg loss: Number(0.5298185450036147)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[293], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m plsfuckingwork \u001b[38;5;241m=\u001b[39m Model(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m10\u001b[39m, [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     plsfuckingwork\u001b[38;5;241m.\u001b[39mtrain_epoch(fixed_x, fixed_y, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10e-2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[270], line 67\u001b[0m, in \u001b[0;36mModel.train_epoch\u001b[1;34m(self, x, y, lr)\u001b[0m\n\u001b[0;32m     57\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y)):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m#     for layer in self.layers:\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m#         for w in layer.flat:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m#         for b in bias.flat:\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m#             b.null_gradients(recursive=False)\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfd(x[i])\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# mse = np.sum((pred * pred +  y[i] *  y[i] - 2 * np.dot(pred, y[i]))) / len(y)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((a \u001b[38;5;241m-\u001b[39m b)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pred, y[i]))\n",
      "Cell \u001b[1;32mIn[270], line 36\u001b[0m, in \u001b[0;36mModel.fd\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# print(np.max(x))\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[i]\n\u001b[0;32m     37\u001b[0m     x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases[i]\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_states\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[1;32m~\\Downloads\\scritch_scratch\\basics\\grad.py:260\u001b[0m, in \u001b[0;36mNumber.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(Add, \u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32m~\\Downloads\\scritch_scratch\\basics\\grad.py:255\u001b[0m, in \u001b[0;36mNumber._op\u001b[1;34m(Op, a, b)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m#Basically op is a class, and we make an istance of that class of f.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Get the output of the operation's forward pass, which is an int or float.\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;124;03m    Make it ans instance of `Number`, whose creator is f. Return this result.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 255\u001b[0m ans \u001b[38;5;241m=\u001b[39m Number(f(a,b), creator\u001b[38;5;241m=\u001b[39mf)\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ans\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Moment of truth\n",
    "plswork = Model(28*28, 10, [4, 8])\n",
    "for i in range(100):\n",
    "    plswork.train_epoch(fixed_x, fixed_y, lr=10e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915796d0-606b-4d94-bd5a-8d301fb40e51",
   "metadata": {},
   "source": [
    "# still in shock that it actually works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "c865b348-9949-4b77-8749-e95f20828496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAEJCAYAAACHTYVNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACtUlEQVR4nO3SQQ0AIBDAMMC/50PFQkJaBXtsz8wsCJ3XAfzPZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkLlEkBg42u6UrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAEJCAYAAACHTYVNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACtUlEQVR4nO3SQQ0AIBDAMMC/50PFQkJaBXtsz8wsCJ3XAfzPZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkLlEkBg42u6UrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAEJCAYAAACHTYVNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACtUlEQVR4nO3SQQ0AIBDAMMC/50PFQkJaBXtsz8wsCJ3XAfzPZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkTEbOZORMRs5k5ExGzmTkLlEkBg42u6UrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAAHTCAYAAABP+gU5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/yklEQVR4nO3dd3xUVf7/8c+kkkIJJHRMMJRQBBRBxC+GImJBBQW7gIhlRVEsrKuINNldUdZ1kRVB5SeriKCwFlS6LtJERZCmlIAIoQepCZOc3x8uWW4+A5lM5kxJXs/Hw8djzztn7pzrHu/kkzvnHpcxxggAAAAA+FlEsAcAAAAAoGyi2AAAAABgBcUGAAAAACsoNgAAAABYQbEBAAAAwAqKDQAAAABWUGwAAAAAsIJiAwAAAIAVFBsAAAAArLBWbLhcLq/+Wbx4sa0hlHqcGRkZQR2bt/r16ydpaWle9f3uu+/kiiuukMTERKlSpYrceOONsnXrVrsDDIJwmH/5+fkybtw4ueqqq6Ru3boSHx8vTZo0kaeeekpycnKCNq6SYv5p4TD/RESWLFkiAwYMkNatW0tsbKy4XC7JysoK6phKytv5VxbOtSTCZQ6KhP91gWugFk7z7zRjjFx++eXicrnkoYceCvZwvFaS+XdaoM81ytaBly1b5miPGjVKFi1aJAsXLnTkTZs2tTUErxQdp4jIihUr5NFHH5WePXsGYUT2bNy4UTp27CitWrWS999/X06ePCnDhg2TDh06yOrVqyUlJSXYQ/SbcJh/J06ckOHDh8ttt90mAwYMkOTkZPnuu+9k9OjR8vHHH8uqVaskLi4uaOPzN+ZfaM0/EZEFCxbI/Pnz5cILL5RKlSqF1Ae/v5WncxUJnzlYnq4L5elcw2X+nenVV1+VzZs3B3sYARHwczUB0rdvX5OQkFBsv2PHjgVgNOfWr18/43K5zM8//2z1fY4fP24KCgpKfZy+ffua1NTUYvv17t3bJCcnm8OHDxdmWVlZJjo62gwZMqTU4whloTj/3G632b9/v8pnzJhhRMRMnTrV6vsz/wInFOefMcbk5+cX/u+xY8caETHbtm0LyHsHev4F81xDQajOwWBeF7gGBk6ozr/Ttm3bZhITE82HH35oRMQMHDjQ+nsGev6dFoxzDeqajY4dO0rz5s3lq6++kvbt20t8fLz0799fRH6/BTd8+HD1mrS0NOnXr58jy87Olvvvv1/q1q0rMTExUr9+fRkxYoS43e4Sj+nIkSMyY8YMyczMlAYNGhTb//QtqIkTJ0qjRo0kNjZWmjZtKu+9956j35QpU8TlcsncuXOlf//+kpKSIvHx8ZKbmysiItOnT5dLL71UEhISJDExUbp16ybff/+9er8pU6ZI48aNJTY2Vpo0aSJvv/22V+fldrvlk08+kZtuukkqVapUmKempkqnTp1k1qxZXh2nLAn2/IuMjJRq1aqpvG3btiIi8ssvvxR7Dsy/8BXs+SciEhFRuo+AcJl//jjXsijYc9Af14VwmYNcA7Vgz78z3XfffdK1a9cSf6MlXOafP861NKx9jcpbu3fvljvvvFOGDBkiY8aMKfEHQnZ2trRt21YiIiJk2LBhkp6eLsuWLZPRo0dLVlaWvPXWWyU63nvvvSfHjh2TAQMGeP2ajz76SBYtWiQjR46UhIQEmTBhgtx2220SFRUlvXr1cvTt37+/XHvttTJ16lQ5duyYREdHy5gxY2To0KFy9913y9ChQyUvL0/Gjh0rHTp0kJUrVxbeZpwyZYrcfffdcsMNN8hLL70khw8fluHDh0tubm6x/962bNkiJ06ckBYtWqiftWjRQubNmycnT56UChUqeH3eZUGozT8RKbzN3KxZM6/6M//CVyjOv5IKh/mHswvmHPTXdSEc5iDXQM9C4Ro4efJkWblypaxfv96ncwiH+eevc/WZ9Xsn/+XpFlpmZqYREbNgwQLVX0TMc889p/LU1FTTt2/fwvb9999vEhMTzfbt2x39XnzxRSMiZt26dSUa5yWXXGKqVKliTpw44VV/ETFxcXEmOzu7MHO73SYjI8M0aNCgMHvrrbeMiJg+ffo4Xr9jxw4TFRVlHn74YUd+5MgRU7NmTXPzzTcbY37/CkDt2rXNRRdd5LjtdvoWbHG30L7++msjImbatGnqZ2PGjDEiYnbt2uXVOYejcJl/O3fuNDVq1DAXX3yx42sfZ8P8Cw/hMP98+WpRuMy/ovga1e+CPQf9cV0IlznINTD05p8xv3/mVq5c2UycONHx3t5+tShc5p8/zrU0gv7noKSkJOncubPPr//kk0+kU6dOUrt2bXG73YX/XH311SIi8uWXX3p9rHXr1smKFSvkjjvuKNFfF7p06SI1atQobEdGRsott9wimzdvlp07dzr63nTTTY72F198IW63W/r06eMYf4UKFSQzM7NwEeOmTZtk165dcvvtt4vL5Sp8fWpqqrRv397rsZ752pL8rKwKpfl38OBBueaaa8QYI9OnT/f6LxXMv/AVSvPPV+E0/6CFwhws7XUhnOYg10CnYM+/Bx54QFq2bCn33nuvz2MIl/nnj3P1VdC/RlWrVq1SvX7Pnj3y8ccfS3R0tMef79+/3+tjvfHGGyIiJfoKlYhIzZo1z5odOHBA6tatW5gXPd89e/aIiEibNm08Hvv0L5wHDhw453sV9wjH02sDTh/nTAcPHhSXyyVVqlQ55zHKolCZf4cOHZKuXbvKr7/+KgsXLpTzzz/f6zEw/8JXqMy/0giH+YezC+Yc9Nd1IRzmINdAz4I5/2bOnCmff/65LFmyRA4fPuz4WV5enuTk5EhCQsJZj31aOMw/f52rr4JebJytko+NjS1cOHOmov+hJicnS4sWLeT555/3eJzatWt7NY68vDyZOnWqtG7dWlq1auXVa07Lzs4+a1Z0AXDR801OThaR3ydCamrqWd/j9HHO9V7nkp6eLnFxcbJ27Vr1s7Vr10qDBg3K3XdFRUJj/h06dEiuuOIK2bZtmyxYsMDjd3rPhfkXvkJh/pVWOMw/nF0w56C/rgvhMAe5BnoWzPn3448/itvtlnbt2qmfTZo0SSZNmiSzZs2SHj16nOMMwmP++etcfRX0YuNs0tLSZM2aNY5s4cKFcvToUUfWvXt3mTNnjqSnp0tSUpLP7/fRRx/J/v37ZeTIkSV+7YIFC2TPnj2Ft9Hy8/Nl+vTpkp6e7qhoPenWrZtERUXJli1b1O21MzVu3Fhq1aol06ZNk8cee6xwwm7fvl2WLl1a7C8VUVFRct1118mHH34oL7zwglSsWFFERHbs2CGLFi2SwYMHl+SUy7xAzb/ThcbWrVtl3rx5cuGFF5b4GMy/sifQ17/SCIf5h5ILxBz013UhHOYg18CSCcT869evn3Ts2FHlnTp1kh49esgjjzwizZs3L/Y44TD//HWuvgrZYuOuu+6SZ599VoYNGyaZmZmyfv16GT9+vFSuXNnRb+TIkTJv3jxp3769DBo0SBo3biwnT56UrKwsmTNnjrz22mvF/p8t8vtXqOLi4uT2228v8ViTk5Olc+fO8uyzzxY+iWDjxo3q0WeepKWlyciRI+WZZ56RrVu3ylVXXSVJSUmyZ88eWblypSQkJMiIESMkIiJCRo0aJQMGDJCePXvKvffeKzk5OTJ8+HCPt9U8GTFihLRp00a6d+8uTz31VOGGQsnJyfL444+X+LzLskDMvxMnThQ+3u7ll18Wt9sty5cvL/x5SkqKpKenFztW5l/ZE6jr3759+wq/03z6L66fffaZpKSkSEpKimRmZhY71nCZf/441/IkUHPQH9eFcJmDXAO9F4j5l5aWdtadt+vUqePxl3NPwmH++etcfWZ9Cfp/ne1JBM2aNfPYPzc31wwZMsTUq1fPxMXFmczMTLN69Wr1JAJjjNm3b58ZNGiQqV+/vomOjjZVq1Y1rVu3Ns8884w5evRosWPbsWOHiYiIUE8J8Ib8dyX/hAkTTHp6uomOjjYZGRnmnXfecfQ7/SSCb775xuNxZs+ebTp16mQqVapkYmNjTWpqqunVq5eZP3++o9/kyZNNw4YNTUxMjGnUqJF58803S7Shy6pVq0yXLl1MfHy8qVSpkunRo4fZvHlzic873ITi/Nu2bZsRkbP+U/R9PGH+hYdQnH/GGLNo0aKzzr/MzMxizyuc5l9pzzXcheocNKZ014VwmoOlPddwFsrzrygp4dOowmn+leZcS8P13zeDj1wulwwcOFDGjx8f7KGgHGL+IZiYfwg25iCCifnnnaA/+hYAAABA2USxAQAAAMAKvkYFAAAAwArubAAAAACwgmIDAAAAgBUUGwAAAACs8HpTv64RvW2OA2FqXsGMgLwP8w+eBGr+iTAH4RnXQAQT8w/B5O38484GAAAAACsoNgAAAABYQbEBAAAAwAqKDQAAAABWUGwAAAAAsIJiAwAAAIAVFBsAAAAArKDYAAAAAGAFxQYAAAAAKyg2AAAAAFhBsQEAAADACooNAAAAAFZQbAAAAACwIirYAwDKg6zRl6osv4JxtFOa7VN9lrX8wKvjpy+8W2UVV8Y52jVeWerVsQAAAPyFOxsAAAAArKDYAAAAAGAFxQYAAAAAKyg2AAAAAFjBAnHAzw592lBlP7Ya79OxTpni+4iIbOw0WWXvXFzL0X5/Xqbqk7/hZ5/GBXjD1bqZo/3pR1NVnwtee0hl9UbxMIPyKLJKZZVtGn++yjxd74buba2ytXc0crTz1/9UitEB8BV3NgAAAABYQbEBAAAAwAqKDQAAAABWUGwAAAAAsIIF4kApeFoM/nWr93w61ms5eiHkuGVdVZaWqncan9v0Q5XdUXG3o/18v2TV5/w/skAc9uxtU8nRdku+6hO/y8unIKDMK6hfV2VrO05UmacHZ4yu/q3KWvZs72jXY4F4uZXf6SKVPfT6+472Pxs2CNRwzunILe1UVmX1fkc7f9PmQA3HL7izAQAAAMAKig0AAAAAVlBsAAAAALCCYgMAAACAFSwQB7zk7qJ3qF3Y8lUPPaNV8vKhRipbdMvFzmDXXtWn0aFVKouoUEFlY1ZcoLKnk9c62u4kt+oD2HSohXNB+E53rupT7Y1lgRoOQkxUPeeC8Pqvh9eiV4SP7d1iVVY18mgQRlK87GvzVHbqLue9gardAzUa/+DOBgAAAAArKDYAAAAAWEGxAQAAAMCKkF6zceDeSx3t8+7S3+fcuLeGyvJy9Xfm60zTWfxO5/f1ClavL+kQUY4crROjsggP9bqn9RmLr9drKvK3bvJpHJtHXKiyd6u+5KGn8zuqdT/nbwuwx1zWSmX/6T7O0c786mHVp4F8b2tICCE7hrVXWeurnJ+5L9T6j1/fM7G9cwPUX57VY0heo9eyxf17pV/HgcByRevP6s6dVwd+ID6q+L1el3nzPV862ouq6A0w83MOWxtTafHbBwAAAAArKDYAAAAAWEGxAQAAAMAKig0AAAAAVoT0AvEhT77raN+UcEh3SvfyYB11lOU+7mj/fV8nLw8WeCv3pjraCS9VVn2iFnwbqOGUS1Xe1puP9Vp1p8pch35TmXt3lt/GMeCa+SpLjNAbFgGBdLBpnMpqRcY72nVm6gd1oHxYc/8/VHbK5Hvo6T+LW77jDFrqPrOO1VLZm0d6qCxqIZ+v4eJIz4tU9kodPf+azH7I0W4oK6yNqSRyk4zKBiVtdLQXV2yiX8gCcQAAAADlDcUGAAAAACsoNgAAAABYQbEBAAAAwIqQXiD+ytO3OtrDWujaKGmDXkhzqIlLZTEtclT2QvMPHe2/1dKLgz49nqiya+OPqswbJ0yeylbkJqisY4VT+sVFxtbglvtVl0YLfBoWSiF//U9Wj5/1/KUqu6fKix566h1HH9/dztGuOH+D6mN3eSbKky4P6gcozD5WxdFOXLxJ9WEOlj3Ri/Wi62hXpNX3/D6vQGVZp1Ic7Z4JB1WfmxP36mzq6yrrXqd1KUYHW8xlrVT26l//rrJ//Zaqsoyhzs/vULkWXXrlj8Eegt9xZwMAAACAFRQbAAAAAKyg2AAAAABgBcUGAAAAACtCeoF4wswVRdreva6Sl8f/R82Ojvboy9L0sb7crLIXOjbw8h2cok7oBWwJa3arrNpXH6jsghjnzrvxWezEW9bk3KUXg3/dRy8GrxyhF4Mvy9WLL1ePvtDRjvttZSlGB/xPZLPGKhtTfZrK3vitrqOdH8I73MI3J3q0VdndtWaozNNu4b7uIN58wQMqS1kQq7LYw87j/6mj/vvq2t6vePWeO//U3tGu++elXr0Odh3603GV1Y1yq+yxh69VWfSh4O8KH1WrpsreOu9zlZ0y4X1vILxHDwAAACBkUWwAAAAAsIJiAwAAAIAVFBsAAAAArAjpBeK2ubP3ONoJH+xRfTwtX0uYecBvY9gzQC8Kbhaj/2958aBzQWbaW1tVH70kCuFk/0VGZZ4Wg3vSd/EAlTWazYJw2PFr12pe9fv2SNFde0/4fzAIGE8PBhg9Tu+2fXFMnqdXF3v8Wcf0zuNDF92ksiZDNqos/7ffij1+458bqWzl9foa2zb2pMo++8MLjvaVFYaoPmlj9IJjk5tb7LjgnQP36t+XZlwwVmVvH26hsuj5wV8M7sn6kfVU5unBCX2zrnC08/fuszYmG7izAQAAAMAKig0AAAAAVlBsAAAAALCiXK/ZCLSoVP3dvPFPj1dZtEt/t3XG353f16u2e5n/BoagyJvn/D77soyXPPTS3yduuayvypo8vkVlvm2XBRTvt6anvOq3enwrR7uKcN0KZwUe1hN6Xp/hnf7br3K0j9wSp/o02qnXnvl6bctf/5PKHpyiNwhcdf/LKqsV6Rzbd/foPjd9qK/N5ocN3g8Q5xTRY7/KakfpzRzfePcqldWV4G/C6GnN07+6TFRZrtHX1x3jnOuNEnJXqD6hjDsbAAAAAKyg2AAAAABgBcUGAAAAACsoNgAAAABYwQLxANo4uI7K2sS6VLYuT298VXX9cStjQmBEnZ+mslENZjjaSR428PvWw35QqaP08sj8Q4d8HhtwLrlXt1HZv6/8h8pG7m+tsqofrHG0C/w3LISZp/dcrLLfBjg3h8zf+XOghlMo7QO96PjZHu1U9pea3wRiODhDZEqKoz200adeva7umOAvBvdk44NVVHZxrP48f/VQU5UlfBBeC8KL4s4GAAAAACsoNgAAAABYQbEBAAAAwAqKDQAAAABWsEDcotxrnQsrv+v1Nw+99O6Xf3jkEZXFLdW7qCJ8pL//q8oujCm+1r9tgd7dttEPLFRE4OzsrD8mWsTohxn0zbpAZdWPbbQyJoSOaFekV/3WXGQ8pIFfEK649ENaoiL0owy8Oc9dI3RWs4cvg4KIiCveeZ3pFn9Y9Wn7TR+V1ZTQ3LU9Oe2gV/3e2aYfppAsP/l7OAHFnQ0AAAAAVlBsAAAAALCCYgMAAACAFRQbAAAAAKxggbhFO6521nKJLr0Y/LZtXVUW//kPKvO0tA6h6VDfS1U2osZLHno650PfrCtUjyZDNqtM7zcK2JPSfK/K8o1eQBv176RADAdBtOkP8So7ZcL7ipR1YzWVzUzRD2Q5ZSKLtPV5135OH1//lwJvFRzMcbRH7btI9bk9fZXKvqqVrjL37my/jctbUan1HO2vW73noZf+m/+J5cke+rFAHAAAAAAUig0AAAAAVlBsAAAAALCCYgMAAACAFSwQ95OIihVVdleHJY72bwUnVZ+9Y85XWWwuO0SHi6g6tVXWYdAKlSVG6IcDFLVsfQOVNTrEXEDgRNVPVdmLjWeobNLheiqr+uYyK2NC6Bja4eNgD6FEourVdbSPtNbX69funuDTsVfmVlCZK8/t07HgWcGRI4723F8zVJ//tHpXZbs/qaz7TdQPbvFVTlP9yJ7ENL27ebvaWY52gZePC3CVwScCcWcDAAAAgBUUGwAAAACsoNgAAAAAYAVrNvzk5+HNVPZJsvO7oDf8fJPqEzuH7+SHsw1P6++uz67p3feaO63t7WizgR+C7ef79Xfa23lYbnTvd51UVk9+tDEkwGfrR9R0tNddOd7nY31w1LnR2j+f6K36VNigNwOE/ySN0OtkMoffprJZzaeo7K/P+W9N2arcSJXle/jb/cUxeUUSl1fHP+8fa1UW7ptDcmcDAAAAgBUUGwAAAACsoNgAAAAAYAXFBgAAAAArWCDug8N3tlPZmlteUdkW9ylH++hf66o+sbLbfwNDwH17/d88pMVv4CciUvlB55Iv96FDfhgR4LuCenrjUU9O5OiFmkAwRS+upbI/1/rAb8ef8mt7R7vCxywGD7iVeuF05Wt0t7s6DlJZTkPvPpe9UW2Sd4vNf/3Q+eCgby+Z4tXrim5mWBZwZwMAAACAFRQbAAAAAKyg2AAAAABgBcUGAAAAACtYIF6MqDp6R91Hn52usliX/ld56w93Odopn7FbOP7nVI3KjnZ0Xh2/Hj9/335H2+Tmqj6uWL1oLjIlWWXq2ClVVPbz4zHeD64Ik+/cWTXjYQ+7qf/2m8/Hh3cmXPIvr/rV+UzvoIuyL9Kl9zGOdnk3F367XT9YpagRI99QWac47x5a4Gkcp0x+kcT3eWs6/+rzaxFYkYu/U1m1xYEehciJrIrO4BLvXmcua6Uy19erSz2eYOLOBgAAAAArKDYAAAAAWEGxAQAAAMAKig0AAAAAVrBA/AyuKP2vo+UnO1XWO/GAyt45Ul1lNZ511nJ6aR3Ks09nvmn1+O2/v83R3r+nkuqTlKJ3Kl3R+l1rY/JW06EPqez8Id7t2grvnbyuraP9fxU87YrMxwR+95fpvVR28z0ve/Xar8a+qjK9gFs7Zbw6/FleW/zxPWm+4AGVNRS96Bg4J+dzTyTCy7/vh/ticE+4swEAAADACooNAAAAAFZQbAAAAACwgi/jnqllYxWNqj7Vq5e+Oqa3yqr8wHfMy7ob1t+hsgXNZwZhJNrSC6f57VjHTZ6jfcp4twLpmjX9VHZ4dfGbBtZZ4vbq+CidHdc7vxDvaXPSkfsvUFniv79VWSm+Wo8wcf70/SpbeWcFlbWN9W4jPttW5jrH9np2pupz6MGaKsvY5mFTUf8NC+VFkYtiQTleucudDQAAAABWUGwAAAAAsIJiAwAAAIAVFBsAAAAArCjXC8QjmzZytO97799eva7pmwNVljZ1uV/GhPAS122bypqN0RvSGR//S6uYcVBlvm661+w/d6vM7Ejw6rXnzzzqDFau9ep1SfKzVxnsi6ykN3X842Vzin3du59drrLz3Tz8ojzKX/+TyoY9NkBlv1ynF8L+dPVEK2M6lwffdG7OV+/5pR56HQrMYFDuFFQofkH4vvzcAIwk+LizAQAAAMAKig0AAAAAVlBsAAAAALCCYgMAAACAFeV6gfjGB5Mc7evif/PqdXUX5+nQsH8uflf/abuLZ7tLa59eV1/W+HkkCCcFuXoh4vrjtR3tK369WPVpOGadythNGafF/Xulyhp5eNbK5bfpB6tE99vjaH/ebLrqc+WPt6qsYEp1lRmXfs+01fscbeYtAulfV73maG/I0wvGb5syRGXniacHGYQ37mwAAAAAsIJiAwAAAIAVFBsAAAAArKDYAAAAAGBFuVkgfvK6tipbcN1LRZL4wAwGAALMeFggvqnIevAY2a76sKgW/lBp2nIdTnM2e4r+nE6QrR6O5inTmLsIppHbrne0j02oo/qc90HZWwzuCXc2AAAAAFhBsQEAAADACooNAAAAAFZQbAAAAACwotwsEN91WaTKzosqfkH4O0f0TqXRv+kdxNk/HAAAACIi0mWno5kgO8/SsezjzgYAAAAAKyg2AAAAAFhBsQEAAADAinKzZsMbfz7QVGXLuqWpzOxeG4DRAAAAAOGNOxsAAAAArKDYAAAAAGAFxQYAAAAAKyg2AAAAAFhRbhaIn//UMpVd89RFXrwy2/+DAQAAAMoB7mwAAAAAsIJiAwAAAIAVFBsAAAAArKDYAAAAAGCFyxhjgj0IAAAAAGUPdzYAAAAAWEGxAQAAAMAKig0AAAAAVlBsAAAAALCCYgMAAACAFRQbAAAAAKyg2AAAAABgBcUGAAAAACsoNgAAAABYQbEBAAAAwAqKDQAAAABWUGwAAAAAsIJiAwAAAIAVFBsAAAAArKDYAAAAAGAFxQYAAAAAKyg2AAAAAFhBsQEAAADACooNAAAAAFZQbAAAAACwgmIDAAAAgBUUGwAAAACsoNgAAAAAYAXFBgAAAAArKDYAAAAAWEGxAQAAAMAKig0AAAAAVlBsAAAAALCCYgMAAACAFRQbAAAAAKyg2AAAAABgBcUGAAAAACsoNgAAAABYQbEBAAAAwAqKDQAAAABWUGwAAAAAsIJiAwAAAIAVFBsAAAAArKDYAAAAAGAFxQYAAAAAKyg2AAAAAFhBsQEAAADACooNAAAAAFZQbAAAAACwgmIDAAAAgBUUGwAAAACsoNgAAAAAYAXFBgAAAAArKDYAAAAAWEGxAQAAAMAKig0AAAAAVlBsAAAAALCCYgMAAACAFRQbAAAAAKyg2AAAAABgBcUGAAAAACsoNgAAAABYQbEBAAAAwAqKDQAAAABWUGwAAAAAsIJiAwAAAIAVFBsAAAAArKDYAAAAAGAFxQYAAAAAKyg2AAAAAFhBsQEAAADACooNAAAAAFZQbAAAAACwgmIDAAAAgBUUGwAAAACsoNgAAAAAYAXFBgAAAAArKDYAAAAAWEGxAQAAAMAKig0AAAAAVlBsAAAAALCCYgMAAACAFRQbAAAAAKyg2AAAAABgBcUGAAAAACsoNgAAAABYQbEBAAAAwAqKDQAAAABWUGwAAAAAsIJiAwAAAIAVFBsAAAAArKDYAAAAAGAFxQYAAAAAKyg2AAAAAFhBsQEAAADACooNAAAAAFZQbAAAAACwgmIDAAAAgBUUGwAAAACsoNgAAAAAYAXFBgAAAAArKDYAAAAAWEGxAQAAAMAKig0AAAAAVlBsAAAAALCCYgMAAACAFRQbAAAAAKyg2AAAAABgBcUGAAAAACsoNgAAAABYQbEBAAAAwAqKDQAAAABWUGwAAAAAsIJiAwAAAIAVFBsAAAAArKDYAAAAAGAFxQYAAAAAKyg2AAAAAFhBsQEAAADACooNAAAAAFZQbAAAAACwgmIDAAAAgBUUGwAAAACsoNgAAAAAYAXFBgAAAAArKDYAAAAAWEGxAQAAAMAKig0AAAAAVlBsAAAAALCCYgMAAACAFRQbAAAAAKyg2AAAAABgBcUGAAAAACsoNgAAAABYQbEBAAAAwAqKDQAAAABWUGwAAAAAsIJiAwAAAIAVFBsAAAAArKDYAAAAAGAFxQYAAAAAKyg2AAAAAFhBsQEAAADACooNAAAAAFZQbAAAAACwwlqx4XK5vPpn8eLFtobglSVLlsiAAQOkdevWEhsbKy6XS7KysoI6ppLq16+fpKWlFduvLJyrt8Jl/p3JGCOXX365uFwueeihh4I9HK95O//OFK7n6q1wmX/GGHnllVckIyNDYmNjpVatWvKHP/xBDh06FNRxlQTXP8/CZQ7269fP47gyMjKCOq6SKMk18LvvvpMrrrhCEhMTpUqVKnLjjTfK1q1b7Q4wCMJl/pWna2AwzzXK1oGXLVvmaI8aNUoWLVokCxcudORNmza1NQSvLFiwQObPny8XXnihVKpUKegT36bydK7hMv/O9Oqrr8rmzZuDPYyAKOvnGi7z74knnpCXX35ZnnjiCbniiitk/fr1MmzYMPnmm29k2bJlEh0dHdTx+VN5uv6JhM8cFBGJi4tT44qLiwvSaOzZuHGjdOzYUVq1aiXvv/++nDx5UoYNGyYdOnSQ1atXS0pKSrCH6DfhMv/K0zUwqOdqAqRv374mISGh2H7Hjh0LwGj+Jz8/v/B/jx071oiI2bZtW0De+/jx46agoKDUx+nbt69JTU0ttl8wzzXYQnX+nbZt2zaTmJhoPvzwQyMiZuDAgdbfM9Dz77RgnGuwheL827lzp4mMjDQPP/ywI3/33XeNiJjXX3/d6vtz/QusUJyDxng/LhsCPQd79+5tkpOTzeHDhwuzrKwsEx0dbYYMGVLqcYSyUJx/5ekaGOxzDeqajY4dO0rz5s3lq6++kvbt20t8fLz0799fRH6/BTd8+HD1mrS0NOnXr58jy87Olvvvv1/q1q0rMTExUr9+fRkxYoS43e5ixxARUbp/Bae/BjJx4kRp1KiRxMbGStOmTeW9995z9JsyZYq4XC6ZO3eu9O/fX1JSUiQ+Pl5yc3NFRGT69Oly6aWXSkJCgiQmJkq3bt3k+++/V+83ZcoUady4scTGxkqTJk3k7bff9nqspT3XsiYU5t9p9913n3Tt2lV69uxZonMIp/lX2nMta4I9/5YvXy75+flyzTXXOPLu3buLiMgHH3xQ7DmE0/zj+qcFew76Q7jMQbfbLZ988oncdNNNUqlSpcI8NTVVOnXqJLNmzSrFv4XwFOz5V56ugf4419Kw9jUqb+3evVvuvPNOGTJkiIwZM6bEHwjZ2dnStm1biYiIkGHDhkl6erosW7ZMRo8eLVlZWfLWW29ZGvn/fPTRR7Jo0SIZOXKkJCQkyIQJE+S2226TqKgo6dWrl6Nv//795dprr5WpU6fKsWPHJDo6WsaMGSNDhw6Vu+++W4YOHSp5eXkyduxY6dChg6xcubLwNuOUKVPk7rvvlhtuuEFeeuklOXz4sAwfPlxyc3P5IPVRKMy/yZMny8qVK2X9+vU+nUM4zb/SnmtZE8z5l5eXJyIisbGxjjw6OlpcLpesWbPGqzGE0/yDFgrXwBMnTkjNmjVl3759UqtWLenRo4eMHDlSqlat6tUYwmEObtmyRU6cOCEtWrRQP2vRooXMmzdPTp48KRUqVPDqnMsKroGBmX/+OlefWb1vcgZPt9AyMzONiJgFCxao/iJinnvuOZWnpqaavn37Frbvv/9+k5iYaLZv3+7o9+KLLxoRMevWrfN6jL7cWhcRExcXZ7Kzswszt9ttMjIyTIMGDQqzt956y4iI6dOnj+P1O3bsMFFRUerW1pEjR0zNmjXNzTffbIz5/SsAtWvXNhdddJHjttvpW7Al+RqLMeXvawShOv927txpKleubCZOnOh4b2+/WhRO86+05xrOQnH+rV692oiIGTVqlCNfsGCBERETExNT7HmF0/w7U3m7/hkTmnPQGGPGjRtnxo0bZ+bOnWvmzp1rnnnmGRMfH28yMjLMkSNHij2vcJmDX3/9tRERM23aNPWzMWPGGBExu3btKvZ8w1Uozr/ydA30x7mWRtD/HJSUlCSdO3f2+fWffPKJdOrUSWrXri1ut7vwn6uvvlpERL788kt/DfWsunTpIjVq1ChsR0ZGyi233CKbN2+WnTt3OvredNNNjvYXX3whbrdb+vTp4xh/hQoVJDMzs3AR46ZNm2TXrl1y++23i8vlKnx9amqqtG/f3t7JlXHBnn8PPPCAtGzZUu69916fxxAu888f51rWBHP+tWzZUi6//HIZO3aszJgxQ3JycmTp0qXywAMPSGRkpNd/YQyX+QfPgn0NHDx4sAwePFi6du0qXbt2ldGjR8vbb78tGzdulEmTJnk1hnCag2e+tiQ/K6u4BgZm/vnrXH0V9K9R1apVq1Sv37Nnj3z88cdnXUW/f//+Uh3fGzVr1jxrduDAAalbt25hXvR89+zZIyIibdq08Xjs0xPgwIED53yvsvwIR5uCOf9mzpwpn3/+uSxZskQOHz7s+FleXp7k5ORIQkJCsU+ICIf5569zLWuCff2bMWOG9OvXT26++WYREYmJiZHBgwfL/PnzJScnx6sxhMP8w9kFew560rNnT0lISJDly5d71T8c5mC1atUcxznTwYMHxeVySZUqVc55jLIo2POvPF0D/XGuvgp6sXG2Sj42NrZw4cyZiv6HmpycLC1atJDnn3/e43Fq165d+kEWIzs7+6zZ6QvMaUXPNzk5WUR+/2UsNTX1rO9x+jjnei+UXDDn348//ihut1vatWunfjZp0iSZNGmSzJo1S3r06HGOMwiP+eevcy1rgn39q169usyZM0f27t0r2dnZkpqaKnFxcTJhwgT1XeOzCYf5h7ML9hw8G2OM139tDYc5mJ6eLnFxcbJ27Vr1s7Vr10qDBg3K3XoNkeDPv/J0DfTHufoq6MXG2aSlpakFKwsXLpSjR486su7du8ucOXMkPT1dkpKSAjnEQgsWLJA9e/YU3kbLz8+X6dOnS3p6uqOi9aRbt24SFRUlW7ZsUbfXztS4cWOpVauWTJs2TR577LHCCbt9+3ZZunRpQIqq8iQQ869fv37SsWNHlXfq1El69OghjzzyiDRv3rzY44TD/PPXuZYXgb7+Va9eXapXry4iIq+88oocO3bM680Ww2H+oeSC+Rk8c+ZMOX78uMc/TngSDnMwKipKrrvuOvnwww/lhRdekIoVK4qIyI4dO2TRokUyePBgr861vOAa6OTPa2BpztVXIVts3HXXXfLss8/KsGHDJDMzU9avXy/jx4+XypUrO/qNHDlS5s2bJ+3bt5dBgwZJ48aN5eTJk5KVlSVz5syR11577Zz/Z+/bt6/wO32n/+Lw2WefSUpKiqSkpEhmZmaxY01OTpbOnTvLs88+W/gkgo0bN6pHn3mSlpYmI0eOlGeeeUa2bt0qV111lSQlJcmePXtk5cqVkpCQICNGjJCIiAgZNWqUDBgwQHr27Cn33nuv5OTkyPDhwz3eVrN1ruVFIOZfWlraWXf9rFOnjsdfzj0Jh/nnr3MtLwJ1/Tv9nfj09HTJycmRzz77TN544w0ZM2aMXHTRRV6NNRzmnwjXv5IKxBzcvn273H777XLrrbdKgwYNxOVyyZdffikvv/yyNGvWTAYMGODVWMNlDo4YMULatGkj3bt3l6eeeqpwU7/k5GR5/PHHvTpGecE10P/zzx/n6jOry8/PcLYnETRr1sxj/9zcXDNkyBBTr149ExcXZzIzM83q1avVkwiMMWbfvn1m0KBBpn79+iY6OtpUrVrVtG7d2jzzzDPm6NGj5xzXokWLjIh4/CczM7PY85L/Pk1nwoQJJj093URHR5uMjAzzzjvvOPqdfhLBN9984/E4s2fPNp06dTKVKlUysbGxJjU11fTq1cvMnz/f0W/y5MmmYcOGJiYmxjRq1Mi8+eabXm8oVNpzDWehOv88OT2nStI3HOZfac81nIXq/Js4caJp0qSJiY+PN4mJiaZDhw5m9uzZXp9XOM2/8nz9MyY05+DBgwdNz549TVpamomLizMxMTGmYcOGZsiQISYnJ8er8wqnOWiMMatWrTJdunQx8fHxplKlSqZHjx5m8+bNXr02nIXi/DOmfF0DS3uupeEyxhi75UzZ5nK5ZODAgTJ+/PhgDwXlEPMPwcT8Q7AxBxFMzD/vBP3RtwAAAADKJooNAAAAAFbwNSoAAAAAVnBnAwAAAIAVFBsAAAAArKDYAAAAAGCF15v6dY3obXMcCFPzCmYE5H2Yf/AkUPNPhDkIz7gGIpiYfwgmb+cfdzYAAAAAWEGxAQAAAMAKig0AAAAAVlBsAAAAALCCYgMAAACAFRQbAAAAAKyg2AAAAABgBcUGAAAAACsoNgAAAABYQbEBAAAAwAqKDQAAAABWUGwAAAAAsIJiAwAAAIAVFBsAAAAArKDYAAAAAGAFxQYAAAAAKyg2AAAAAFhBsQEAAADAiqhgDwAAAMC2qJo1VJbXsLZPx4r+6VeVbfrT+Sqrst6lsqobTqos4j/f+zQOIBxwZwMAAACAFRQbAAAAAKyg2AAAAABgBcUGAAAAACtYIG5RTp9LHe0Vf/mn6tP01QdVdt5fV6rMuN3+Gxisikqtp7Lq03NU9uW3TR3tjAm6T/66Tf4all9FpqSo7MDVDVSWNP07lZncXCtjAlB+Hb6zncoOXONciP3UhZ+rPn0qzfHp/d44fJ7Kbqw4S2VJvSt4dbzudVr7NA4gHHBnAwAAAIAVFBsAAAAArKDYAAAAAGAFxQYAAAAAK1gg7idRdfQupKOGTS72desHTlDZ1a90UJk5csS3gcEqTzvSjlz8gcoaRxeorPOBmo52/rqf/TcwPyu6IPyOJXrhd7sKenHkwLX364N9v85v40LpRCZXc7Q3/U0veu3YUM/LXzNPqYyF/yitiJZNVLbx4QSV/efKl1WWEvmNPp7Fv6feU3mHh9S7xeBAecOdDQAAAABWUGwAAAAAsIJiAwAAAIAVrNnwk73dUlV2Zbz+XnNRF626RWUpR3/yy5jgX1F166is8vTjKmsRE6myxvMfUFnDvnrdQ6jaMDrN0b45UW+OddHLQ1RW+/ultoaEEtr7UHuVPffI2472tfFzvTpWj+TrVOb+dZdvAwP+61j9iir76Wq9Ga5InP3BFPFazvmO9jvb2/j1+JVls1+PB/+IaNVUZSdr6nVEWT1cKuvV1rmO6JTRvxssmtpWZbW+PKwyE+ZrHbmzAQAAAMAKig0AAAAAVlBsAAAAALCCYgMAAACAFSwQ90FEfLzKug1a4tOxYt9L0qExPh0Ldh26rJ7KZqe96tVrmwzdqzJ3qUdkh7m0pco2d5/oaGeu7a361Htzo8ry/TcslEBko3SVTX78ZZW1inF+BOitJz3b/U+9kLfW/TVV5t6d7eUREa48PThjwx/rqqzGUr2AttK05Y52RK7+7PvpVJ7KfnFXUVm9qByV9fuxr6N9aEM11afGN/o9qyz9RWXm6FFHu3IOC7rDnbmslaO9daDu8+6lk1TW2sNDYHz25EoVnXhCz/nXc5wL1Sf8kKn6NLxng8oKTp4sxeD8hzsbAAAAAKyg2AAAAABgBcUGAAAAACsoNgAAAABYwQJxH+S2b6Ky0dXfKPZ1xwv0op9K7y730BOhICrVuSB83w3eLbS6+MWHVVbzl9DcSdvTYvCh7/y/Yl939FO9GDjhwFa/jAmlt+Ep/eAJTzvb+2pF63dV9tMyfX27cepjjvb5z3+v+oTKAkYUL7JKZZW1/XSbymYnf6Syy1Y9VOzxYz/7RmVPXttPZfnrNumxNWmosqqbtjjbBT8VOwaR0H14B7xT8H+tVJb1oO736WXOB7ykR3namV5fN+ed0P2eXt9DZTk7qjjaP/b4h+rz7J52Knuh5iqVtYzb7miPaztd9fnT4H4qq/vn0PjdgzsbAAAAAKyg2AAAAABgBcUGAAAAACsoNgAAAABYwQJxH2y70beFlr1+7uEh3VWqscCeX/6e6Gj/3HaK6jN0byuV1XlrncpCdSftXzsmqOyyWL2PdPOlzp14z/tHaCw6g0hk00Yqm9/lZQ899aLGvx5wPuxiVc55qs/09M+9Gkej6BiVTbrjn873e/MG1adg23aVITREVKjgaOfO1AvEn05eqLLGH+rVuBmzfLsueloM7rHfhp+96oeyZeu7rVT2jte7fjuvibdt66p6fLOxvsoyHtE7dacc0/M0pUj7gdZXqD57B6WqbPA/9ViH1ljsaP/nRC3VZ/VDegF6j3/pa677l50qs407GwAAAACsoNgAAAAAYAXFBgAAAAArKDYAAAAAWMECcR9c2+YHr/odLjjhaJ8aXkP1iWCBeMgyxuVonzJ6OeOKA2kqizyx19aQSiSiYkVHe9PzTVWf2dePU1mBRKvsvN5r/Tcw+NX+ttVUlhYVr7L7frlcZTvbHXW0IxKOqz6tH3hYZU/c+77K7qio5/3lzvXF8vEHO1Sf9dfq3ejdu7NVBrsik/Su8xtHOR8+sKnJBNXn21x9rIyRW1WW/9tvvg8O5VJEgvMBJj+PvED12ZD5qsoiPOz6/U2uUdkd/x7oaDceoRd+N8rRu3nrR6h454KKv6psXpRegL5qbGuVVRu3wtHukZDj4R1cHrLQwJ0NAAAAAFZQbAAAAACwgmIDAAAAgBWs2ShG7jVtVDa+jt4wxpOdbmc74svv/TEkhJA5GbNVds/iTirbcURvwJP3hv6uuq+yO+jvo15zyWpH+6Pa+vvW4mF9xmWrb1VZkrBhVqjKj9VZgej5sGai/r5zVVnmfN2xY6pPrZf0Bo7vX6evi7dV/EQPxDi/3bwnt6LuctLDl/4RcLvubKKyTT2dm4R9dEyv63iju94ILX/fFv8NDOVWzvXOa9bC3i+qPhGi16ctOKEvin95sK/KGsxd7miXZvNdV5T+dTqicbqjPXl2VdVn7Nv/T2UXxHha9+k8z0iXvldwwYrbVVZnb2j8t8idDQAAAABWUGwAAAAAsIJiAwAAAIAVFBsAAAAArGCBeDH2tNELaL113SePOtoNZYXnjghJ1f8R52gver2C6tMp7qTK3jhvkcoiPGy2UzBOL+L1lcfje1gkXNS0I3qjyWpP68uCr5sYwb6KN+32qt/hbnrxd9W3fHvPYakfeUiL/9vVf77PUFmjQyt9GwT86sglJ4rt8/dtXVQW91NoLEBF2WOK7M130ni3ad2RgjiVZV8So7ITN7Z1tBs09PJaelL/LtA79TuVDawy1dFelafHcFmsp09Xvei9qK9P6tfVGa3//Zjc0HgAB3c2AAAAAFhBsQEAAADACooNAAAAAFZQbAAAAACwggXixYi58JBX/TbkHVdZxiv7He3S7E6JwIta+K2j/ff/66z6jGqfprKdV+qF2Zuve01lK3Odi7nunPtACUf4Pw3f1ovAPp3xZrGve2F9N5XV+WGdz+NA4B35QO9OL8101K+pfkDFV22cCyT3XZio+pjuB1XWPFov6t5w6pQeRrRzQeSsq/+h+vyx3b16sMvX6AxWTbvsdQ+p8++RM5v+S/W4dNzjKqv/UZ7KIhfrBbTAuST92/lZdF+fO1Sff2XoOXl9gv4MvukPE1SWb4p/9Emucass1uXtr87Ofp4Xg2tuD78tdlxzq6NddaDuY7aG7mc3dzYAAAAAWEGxAQAAAMAKig0AAAAAVlBsAAAAALCCBeJnONm9rcpWtfmnh56RKtl0qrrK8tlZtUxxZ+9RWfyHOmv0oX7tNQ9cVOzxG4nvOylHtNA7MxfdVXz0/uaqT+ojh1Wml8MhlNX8aJvKfvqTXqD7ZLX1Kvvj7A2Otje7zouI3LLlWpWdGJSisp7TFjvad1f6RfXZMkj/zSt9uVfDgB+1jY1W2SnjXISaFKF3Tt54y6v6dTfrxavNF+gHYFT+xnm8o3X1/Ku0VY81ec0xHXqwv0WCo11j8V7Vh8/p0FVw5IijHXvlEdXnvho3qmzD8DSVXdl6rcp+Ouz8vW37r8mqT2SMnsvXN9YPsHih5iqV+arpovtU1vjxXx1t9x49l0MZdzYAAAAAWEGxAQAAAMAKig0AAAAAVlBsAAAAALCCBeJnOJGsF35Hu3TmyZBv9SKl+sIuuAiMHc/peVp0se/c5y9XfRJ/YSVuuHPvzlbZfU8+qrK3XhynskbRzgW04mFH3QZz9Q7fGQ9tVFnBMb0A/S8Lr3O07+mhH7jx14v1ExUmt9QL0At+2KAy+E/9j/X/zz91f82nY3n63Nx0xSTd8QqfDu+zlU+5VPbo+ltVVrX7T4EYDvwg38NC6UZ/0FmWh9fGyHZHu2GR9tnMndVUZd4sEM9yH1dZj38MUVnDl/XDYvLd4f3oFu5sAAAAALCCYgMAAACAFRQbAAAAAKxgzcYZcnvkeNVvQ57+3l3dyXpDJMCG/fddqrI17fTGWlnuE4523D690RvKpsQZK1R2tzymsoM3O69lJw/Hqj5NntSbnuUf825TtcZPOddxdGmo17bNa/aByp57Tv8drI5+Kfyo8cDvVdZthnNzsT7jP1Z94iNyVdY9fp/KvF3/aFPbWL1p4JIL31FZs7GDVJb+5DIrY0Jo2zZGf95+1+ZvHnrGFHusXi/o9Rm1X12qMu+2Vg0v3NkAAAAAYAXFBgAAAAArKDYAAAAAWEGxAQAAAMCKcr1APLJRuqO9qs2/PPVSyWdHm6ssev63/hoWcE7Hux71ql+v1QMc7eqLvrMxHIQJT4vGE2cU/7r8UrxnwZEjjvZvs/S1U5rp6K8t9KLxCbU6OtqeNjOE74yHTcOKfq5Ny6jt1bFe6aU3ysuP1hvqtX/CuXnZX2p+49Xx/SnCw99c67bcHfBxIPh2PdleZV/c8YLK4lzxXh3v74caONo131qt+uhtVMsm7mwAAAAAsIJiAwAAAIAVFBsAAAAArKDYAAAAAGBFuV4gvqdTdUfb2x1Oxy/qqrKGohdfAjZMbD1VZbvz9a721V72bhEbECgpE1eq7JKrb1fZitbvquyRJ9Ic7fTHWSAeqhJmevd5+HFL5+7Mf7lLLxA/bvJU1vqrP6gsdbL+/N4/yHld9PwQGJRXp6682NGe/ZBeDH5elHefozvc+jP4oz92cbRjjwf+AQihgjsbAAAAAKyg2AAAAABgBcUGAAAAACsoNgAAAABYUa4XiJ+sqnc0LerbXL04rclfd6pM770KlN7OP+kdTS+L1TuBL8/Vi9gi2TEcoaZA70de7SU9d/dPPaGyDbe+6mhf924f1cd8u64Ug0OgnfdFrjO4S/eJd8WobEPmGyq7K1U/uGVO2hdFEu/+vroju6rKGkqWV69F+Mjq7nyoQJqXi8E9PZClz6OPqyz+Ux4cdBp3NgAAAABYQbEBAAAAwAqKDQAAAABWlOs1G9U7/1psn49+u1Bl+fv22xgOoNxx2wKVFYhR2T2r+qksVdY62pHV9PeQpXo1FeVv+Nn7AQKlFPHl9yrr+P+eVNn6/s41G0ee1+s6KvWuqLKCI0dKMTrYFL3Kea1p991tqs/yi6Z5daypafM8pM6/p+aaU6pH9/W3qixj0BaV6dVGCCeePv++v/HlIkmsV8fquOQhlaXPYn3GuXBnAwAAAIAVFBsAAAAArKDYAAAAAGAFxQYAAAAAK8rNAnFXrF74c0PtH4p93YG8RJWZ3FwPPYHgKcjXfzfY+5BzQ8BrB/xH9Zm9tZbK6tzov3EBvmjw+i8qm9q7pqP91QUzVZ+rWvZXWcSS1X4bF/yr6OL9mg8nqT7XvXm9yp5O+1Rll8bqJdwfHE12tJ+Zc4vq02DwcpWxGDy8RSbpefToCv35l+gqfkH4Xw80UVnDe/VDVAq8HFt5xZ0NAAAAAFZQbAAAAACwgmIDAAAAgBUUGwAAAACsKDcLxCVfL/l6fcP/OdqPts9SfRb/0kBldWSd34YF+MOGy99SWcHlzp3Gm32lF882GH5MZSyORLC5f9mpsvd7Zjrad82frvrsf/Kkyqov8d+4YJc7a4cOO+to0KAHVXakjd5RPmPofke7wXa9GBxlz/7rM1R2ZfwileUbFSlzRnRUWcIxdgsvKe5sAAAAALCCYgMAAACAFRQbAAAAAKyg2AAAAABgRblZIG7cbpWlPeVcHNvkz3epPq7VFa2NCSjOF89kqmz9n/Su38tW6AVxGX/f5WinZ29SffJP6gW1QCjK3+DctfeWrVeqPh9fOFll97TTi4ll+Rq/jQuBV+OVpTrz0E9/6qM8uOmJ+SrLN8Xv8d3g4wdU1ugDFoP7A3c2AAAAAFhBsQEAAADACooNAAAAAFZQbAAAAACwotwsEPckf/M2R/u83kEaCHAWFT5eqbJ9H+t+DUTvjMviSJRlx3vq7X9XLK2tskONE1SWxEbSQJnVMk7vRB/p0n9bX34y39Fu+sJe1YfPUf/gzgYAAAAAKyg2AAAAAFhBsQEAAADAinK9ZgMAEJ7y9x9Q2euNzldZkiwLxHAAhIhH37lHZRvvnaCy/m8+7GjX26o3i4R/cGcDAAAAgBUUGwAAAACsoNgAAAAAYAXFBgAAAAArWCAOAACAMiH1Ob3Qu9tzrVRWT1gQHijc2QAAAABgBcUGAAAAACsoNgAAAABYQbEBAAAAwAqXMcYEexAAAAAAyh7ubAAAAACwgmIDAAAAgBUUGwAAAACsoNgAAAAAYAXFBgAAAAArKDYAAAAAWEGxAQAAAMAKig0AAAAAVlBsAAAAALDi/wOymxEOAaPAHAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x700 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline  \n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "pic = 1\n",
    "for i, img in enumerate(x_test[:10]):\n",
    "  plt.subplot(2, 5, pic)\n",
    "  plt.axis('off')\n",
    "  predicted = plswork.fd(img.flat)\n",
    "  plt.title(f\"True {y_test[i]} pred {np.argmax(predicted)}\")\n",
    "  plt.imshow(img)\n",
    "  pic+= 1\n",
    "plt.show()\n",
    "#60% acc. Considering this is from nearly scratch not terrible "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b728fc6c-1552-4dc3-a53e-ca813d84c2dc",
   "metadata": {},
   "source": [
    "# What I learned (future me pls remember this):\n",
    "- Early gradients are kinda random. Don't print out the losses after every single image and then spend get sad when its not decreasing right. Even if it's working, only the after 1 epoch will show decreasing trend.\n",
    "- Number class: w-= w.grad kind of created new Numbers, each of which had gradient = to None. This sent me on a wild goose chase debugging why gradients were fine before w-=w.grad and then None after for a long while.\n",
    "- As another side note, no need to null the gradients if I re-make the graph from scratch (and better not to so that the old weights' states aren't remembered/backproped)\n",
    "- The activation fxn Sigmoid goes at the end (not between layers. Otherwise the gradient gets really small and goes poof)\n",
    "- Weights should also be p small unless I want overflow\n",
    "- Topological sort might have a scary name but it was much easier/cleaner than trying to do it the other way. Moral of the story: scary name is not that bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad5302-2901-477d-b940-1dd2990543c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
